{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom PIL import Image\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom torchvision.datasets import ImageFolder\nfrom pathlib import Path","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:34:00.406475Z","iopub.execute_input":"2021-07-15T18:34:00.406833Z","iopub.status.idle":"2021-07-15T18:34:00.411955Z","shell.execute_reply.started":"2021-07-15T18:34:00.406803Z","shell.execute_reply":"2021-07-15T18:34:00.410868Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Create a list of paths of images for training, validation and testing\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\ntrain_dir = Path('../input/100-bird-species/birds/train')\nval_dir = Path('../input/100-bird-species/birds/valid')\ntest_dir = Path('../input/100-bird-species/birds/test')\ntrain_data = ImageFolder(train_dir, transform = transform)\ntest_data = ImageFolder(test_dir, transform = transform)\nval_data = ImageFolder(val_dir, transform = transform)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:34:05.051422Z","iopub.execute_input":"2021-07-15T18:34:05.051767Z","iopub.status.idle":"2021-07-15T18:34:05.816353Z","shell.execute_reply.started":"2021-07-15T18:34:05.051735Z","shell.execute_reply":"2021-07-15T18:34:05.815455Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_data, batch_size = 32, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_data, batch_size = 32, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size = 32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:34:08.990325Z","iopub.execute_input":"2021-07-15T18:34:08.990675Z","iopub.status.idle":"2021-07-15T18:34:08.997885Z","shell.execute_reply.started":"2021-07-15T18:34:08.990645Z","shell.execute_reply":"2021-07-15T18:34:08.997086Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"classes = list(train_data.class_to_idx.keys())","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:34:13.361347Z","iopub.execute_input":"2021-07-15T18:34:13.361735Z","iopub.status.idle":"2021-07-15T18:34:13.367762Z","shell.execute_reply.started":"2021-07-15T18:34:13.361683Z","shell.execute_reply":"2021-07-15T18:34:13.366989Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# neural network architecture\nclass NN(nn.Module):\n      def __init__(self):\n          super(NN, self).__init__()\n          self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5, stride=2)\n          self.batch_norm1 = nn.BatchNorm2d(64)  \n          self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n          self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2)\n          self.batch_norm2 = nn.BatchNorm2d(128)\n          self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n          self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1)\n          self.batch_norm3 = nn.BatchNorm2d(256)  \n          self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2)\n          self.drop_out1 = nn.Dropout(0.5)\n          self.fc1 = nn.Linear(in_features=4*4*256, out_features=2048)\n          self.drop_out2 = nn.Dropout(0.5)\n          self.fc2 = nn.Linear(in_features=2048, out_features=2048)\n          self.drop_out3 = nn.Dropout(0.5)\n          self.fc3 = nn.Linear(in_features=2048, out_features=275)\n      def forward(self, x): \n          output = self.pool1(F.relu(self.batch_norm1(self.conv1(x))))\n          output = self.pool1(F.relu(self.batch_norm2(self.conv2(output))))\n          output = self.pool1(F.relu(self.batch_norm3(self.conv3(output))))\n          output = output.flatten(1)\n          output = self.drop_out1(output)\n          output = F.relu(self.fc1(output))\n          output = self.drop_out2(output)\n          output = F.relu(self.fc2(output))\n          output = self.drop_out3(output)\n          output = F.relu(self.fc3(output))\n          return output\n \nneu_net = NN()\nif torch.cuda.is_available():\n   neu_net.cuda()\nneu_net","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:34:16.396729Z","iopub.execute_input":"2021-07-15T18:34:16.397042Z","iopub.status.idle":"2021-07-15T18:34:16.526903Z","shell.execute_reply.started":"2021-07-15T18:34:16.397014Z","shell.execute_reply":"2021-07-15T18:34:16.525952Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"NN(\n  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2))\n  (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n  (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n  (batch_norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (drop_out1): Dropout(p=0.5, inplace=False)\n  (fc1): Linear(in_features=4096, out_features=2048, bias=True)\n  (drop_out2): Dropout(p=0.5, inplace=False)\n  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n  (drop_out3): Dropout(p=0.5, inplace=False)\n  (fc3): Linear(in_features=2048, out_features=275, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"loss_function = torch.nn.CrossEntropyLoss()\noptimizer = optim.SGD(neu_net.parameters(), lr=0.01, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:16:09.979354Z","iopub.execute_input":"2021-07-15T19:16:09.979704Z","iopub.status.idle":"2021-07-15T19:16:09.985290Z","shell.execute_reply.started":"2021-07-15T19:16:09.979670Z","shell.execute_reply":"2021-07-15T19:16:09.984489Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# calculate training and validation accuracy\nfor epoch in range(1,11):\n    # create a loop to enumerate over batches \n    train_loss = 0\n    val_loss = 0\n    correct_predictions_t = 0\n    total_predictions_t = 0\n    correct_predictions_v = 0\n    total_predictions_v = 0\n    for inputs, labels in train_loader:\n        if torch.cuda.is_available():\n           inputs, labels = inputs.cuda(), labels.cuda()   \n        # zero the parameter gradients\n        optimizer.zero_grad()\n        # forward propagation \n        outputs = neu_net(inputs)\n        # calculate loss \n        loss_func = loss_function(outputs, labels)\n        train_loss += loss_func.item()\n        prediction = outputs.argmax(1)  # calculate the index that has maximum value \n        correct_predictions_t += prediction.eq(labels.data).sum().item()\n        total_predictions_t += labels.size(0)\n        # use the backward call to calculate gradients of loss function wrt the parameters\n        loss_func.backward()\n        # update the values of parameters\n        optimizer.step() \n    for inputs, labels in val_loader:\n        if torch.cuda.is_available():\n           inputs, labels = inputs.cuda(), labels.cuda()   \n        outputs = neu_net(inputs)\n        loss_func = loss_function(outputs,labels)\n        val_loss += loss_func.item()\n        prediction = outputs.argmax(1)  # calculate the index that has maximum value \n        correct_predictions_v += prediction.eq(labels.data).sum().item()\n        total_predictions_v += labels.size(0)\n    print('Epoch: %d  Training Loss: %.5f  Training Accuracy: %.2f %% Validation Loss: %.5f Validation Accuracy:%.2f %%' % (epoch, train_loss / (len(train_loader)), 100*(correct_predictions_t/total_predictions_t), val_loss / (len(val_loader)), 100*(correct_predictions_v/total_predictions_v)))","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:16:12.682838Z","iopub.execute_input":"2021-07-15T19:16:12.683167Z","iopub.status.idle":"2021-07-15T19:34:56.267292Z","shell.execute_reply.started":"2021-07-15T19:16:12.683138Z","shell.execute_reply":"2021-07-15T19:34:56.266422Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Epoch: 1  Training Loss: 0.90388  Training Accuracy: 75.15 % Validation Loss: 1.07462 Validation Accuracy:73.16 %\nEpoch: 2  Training Loss: 0.84563  Training Accuracy: 76.85 % Validation Loss: 1.06170 Validation Accuracy:73.60 %\nEpoch: 3  Training Loss: 0.81018  Training Accuracy: 77.72 % Validation Loss: 0.97563 Validation Accuracy:75.56 %\nEpoch: 4  Training Loss: 0.75868  Training Accuracy: 79.11 % Validation Loss: 1.12146 Validation Accuracy:72.00 %\nEpoch: 5  Training Loss: 0.71794  Training Accuracy: 79.96 % Validation Loss: 1.04641 Validation Accuracy:73.09 %\nEpoch: 6  Training Loss: 0.68926  Training Accuracy: 80.75 % Validation Loss: 1.03026 Validation Accuracy:75.20 %\nEpoch: 7  Training Loss: 0.65088  Training Accuracy: 81.75 % Validation Loss: 1.07713 Validation Accuracy:72.95 %\nEpoch: 8  Training Loss: 0.62217  Training Accuracy: 82.50 % Validation Loss: 1.05445 Validation Accuracy:74.47 %\nEpoch: 9  Training Loss: 0.61228  Training Accuracy: 82.81 % Validation Loss: 1.08245 Validation Accuracy:74.25 %\nEpoch: 10  Training Loss: 0.57654  Training Accuracy: 83.75 % Validation Loss: 1.05312 Validation Accuracy:74.69 %\n","output_type":"stream"}]},{"cell_type":"code","source":"# accuracy on test images\ncorrect_predictions = 0\ntotal_predictions = 0\nfor inputs, labels in test_loader:\n    if torch.cuda.is_available():\n           inputs, labels = inputs.cuda(), labels.cuda() \n           outputs = neu_net(inputs)\n           prediction = outputs.argmax(1)\n           correct_predictions += prediction.eq(labels.data).sum().item()\n           total_predictions += labels.size(0)\nprint('Test_Accuracy: %.2f %%' % (100 * (correct_predictions/total_predictions)))","metadata":{"execution":{"iopub.status.busy":"2021-07-15T20:01:42.570799Z","iopub.execute_input":"2021-07-15T20:01:42.571162Z","iopub.status.idle":"2021-07-15T20:01:52.914880Z","shell.execute_reply.started":"2021-07-15T20:01:42.571131Z","shell.execute_reply":"2021-07-15T20:01:52.913810Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Test_Accuracy: 77.38 %\n","output_type":"stream"}]}]}